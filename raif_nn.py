# -*- coding: utf-8 -*-
"""Raif_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zspkUWWJyL0L0CHEdwf5gVpfPIpL9AIi

#Райфайзенбанк прогнозирование Customer Lifetime Value на 6 месяцев.
Бочаров Алексей(скайп bam271074)

CRM-системы банков собирают большой объем информации, которая используется для анализа бизнес-процессов. 
В рамках работы над кейсом вы получите часть этих данных и решите одну из самых актуальных для Райффайзенбанка 
задач — предсказание размера будущих доходов от сотрудничества с клиентами. Точный прогноз не только поможет 
сформировать лучшие персонализированные клиентские предложения на рынке, но и позволит повысить качество 
среднесрочного планирования, открывая новые горизонты для развития банка.

Использование данных, появившихся после 2018 года, запрещено.
"""

# подгружаем необходимые библиотеки и фиксируем random state

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
RS = 42

pip list

#connect to google drive where dataset is
from google.colab import drive
drive.mount ('/content/gdrive', force_remount = True)

!ls

!ls /content/gdrive/'My Drive'/

print(os.listdir("../content/gdrive"))

data_root = '../content/gdrive/My Drive/'
print(os.listdir(data_root))

"""Let s make dataframes"""

seq_path_train =(data_root, "CL_Cup IT 2020_DS_1/CUP_IT_train_data.csv")
train_df = pd.read_csv("/".join(seq_path_train), sep=',', skip_blank_lines=True, header=133)
train_df.head(4_200_000)

"""Название признака	Описание признака
	
cif_id	Уникальный номер для клиента
	
dlk_cob_date	Временная метка данных в формате YYYY-MM-DD
	
gi_smooth_3m	Доход, который банк получил от данного клиента за данный
	месяц
	
big_city	Город клиента (укрупненный до вариантов Мск/Спб., мил-
	лионник, другой город)
	
cu_gender	Пол клиента
	
cu_education_level	Уровень образования клиента (может быть неактуально)
	
cu_empl_area	Область работы клиента (может быть неактуально)
	
cu_empl_level	Уровень должности клиента (может быть неактуально)
	
payroll_f	Флаг того, что клиент получает з/п на карту банка
	
cur_quantity_pl	Количество персональных кредитов
	
cur_quantity_mort	Количество ипотечных кредитов
	
cur_quantity_cc	Количество кредитных карт
	
cur_quantity_deposits	Количество депозитов
	
cur_quantity_dc	Количество дебетовых карт
	
cur_quantity_accounts	Количество счетов
	
cur_quantity_saccounts	Количество накопительных счетов
	
cur_quantity_mf	Количество инвестиционных продуктов
	
cc_balance	Баланс кредитных карт
	
cl_balance	Баланс автокредитов
	
ml_balance	Баланс ипотеки
	
pl_balance	Баланс кредитов
	
td_volume	Баланс депозитов
	
ca_volume	Баланс счетов

Название признака	Описание признака
	
sa_volume	Баланс накопительных счетов
	
mf_volume	Баланс инвестиций
	
dc_cash_spend_v	Объемы трат с дебетовых карт наличными
	
dc_cash_spend_c	Количество трат с дебетовых карт наличными
	
cc_cash_spend_v	Объемы трат с кредитных карт наличными
	
cc_cash_spend_c	Количество трат с кредитных карт наличными
	
dc_pos_spend_v	Объем POS-транзакций с дебетовых карт
	
dc_pos_spend_c	Количество POS-транзакций с дебетовых карт
	
cc_pos_spend_v	Объем POS-транзакций с кредитных карт
	
cc_pos_spend_c	Количество POS-транзакций с кредитных карт
	
ca_f	Флаг наличия текущего счета
	
rc_session_qnt_cur_mon	Количество сессий в онлайн-банке
	
cur_qnt_sms	Количество полученных СМС
	
active	Является ли клиент активным по определению банка
	
standalone_dc_f	Флаг отдельной дебетовой карты
	
standalone_payroll_dc_f	Флаг отдельной зарплатной карты
	
standalone_nonpayroll_	Флаг отдельной НЕ зарплатной карты
dc_f	
	
salary	Зарплата клиента
	
cu_age	Возраст клиента
	
cu_mob	Сколько клиент уже в банке
	
cu_empl_cur_dur_m	Сколько клиент работает на данной работе (может быть
	неактуально)
	
is_married	Состоит ли клиент в браке
"""

train_df.cif_id.nunique() #number of clients

#let s upload file with test data
from google.colab import files
uploaded = files.upload()
for fn in uploaded.keys():
  print ('User uploaded file {name} with length {length} bytes'.format(name=fn, \
                                                                       length=len(uploaded[fn])))

!ls

#let s build df from uploaded file

test_df = pd.read_csv("CUP_IT_test_data.csv", sep=',', skip_blank_lines=True, header=133)
test_df.head(13)

#let s build df from the file in googledrive

#seq_path_test =(data_root, "CL_Cup IT 2020_DS_1/CUP_IT_test_data.csv")
#test_df = pd.read_csv("/".join(seq_path_test), sep=',', skip_blank_lines=True, header=133)
#test_df.head(13)

"""rank - колонку не используем. ее добавили по ошибке."""

X_colomns = ['cif_id',	'dlk_cob_date',	'gi_smooth_3m', 'cu_age'] #take in work minimum columns

X_work = train_df[X_colomns]
X_work.head(20)

X_work.info() #let s see columns type

X_work.dlk_cob_date =  pd.to_datetime(X_work.dlk_cob_date) # convert object to date
X_work.head(45)

X_work.info()

#lets make new column month
X_work['month'] =  X_work['dlk_cob_date'].map(lambda x: 'month_'+str(x.month))
X_work.head(45)

#lets sort by columns client, month
X_work =  X_work.sort_values(by =['cif_id', 'month'], ascending=[True, True])
X_work.head(4_200_000)

X_work.describe()

X_work.count(axis=0) #let s see if where is NaN in data

#let s make one hot encoding
#X_work.types.astype(str).str.get_dummies()

df_nonbinary = pd.get_dummies(X_work['month'])
df_nonbinary.head(13)

#let s concatenate X_work and df_nonbinary

#Xy= pd.merge(X_work, df_nonbinary)
Xy = pd.concat([X_work, df_nonbinary], axis=1)
Xy.head(13)

Xy.columns

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_1): #make new column Jan with data
  lst.append(n*s) 
Xy['Jan'] = lst

Xy.head()

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_2): #make new column Feb with data
  lst.append(n*s) 
Xy['Feb'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_3): #make new column March with data
  lst.append(n*s) 
Xy['March'] = lst

Xy.head()

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_4): #make new column Apr with data
  lst.append(n*s) 
Xy['Apr'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_5): #make new column May with data
  lst.append(n*s) 
Xy['May'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_6): #make new column June with data
  lst.append(n*s) 
Xy['June'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_7): #make new column July with data
  lst.append(n*s) 
Xy['July'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_8): #make new column August with data
  lst.append(n*s) 
Xy['Aug'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_9): #make new column September with data
  lst.append(n*s) 
Xy['Sep'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_10): #make new column Oct with data
  lst.append(n*s) 
Xy['Oct'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_11): #make new column November with data
  lst.append(n*s) 
Xy['Nov'] = lst

lst = []
for n, s in zip (Xy.gi_smooth_3m, Xy.month_12): #make new column December with data
  lst.append(n*s) 
Xy['Dec'] = lst
Xy.head()

Xy.shape

def my_sum(x_df):
  dfout = sum (x_df['Jan'])
  return dfout
Xy_Jan = Xy.groupby(['cif_id']).apply(my_sum)
Xy_Jan.head(13)

Xy_Jan.shape

def my_sum(x_df):
  dfout = sum (x_df['Feb'])
  return dfout
Xy_Feb = Xy.groupby(['cif_id']).apply(my_sum)
Xy_Feb.shape

def my_sum(x_df):
  dfout = sum (x_df['March'])
  return dfout
Xy_March = Xy.groupby(['cif_id']).apply(my_sum)
Xy_March.shape

def my_sum(x_df):
  dfout = sum (x_df['Apr'])
  return dfout
Xy_Apr = Xy.groupby(['cif_id']).apply(my_sum)
Xy_Apr.shape

def my_sum(x_df):
  dfout = sum (x_df['May'])
  return dfout
Xy_May = Xy.groupby(['cif_id']).apply(my_sum)
Xy_May.shape

def my_sum(x_df):
  dfout = sum (x_df['June'])
  return dfout
Xy_June = Xy.groupby(['cif_id']).apply(my_sum)
Xy_June.shape

def my_sum(x_df):
  dfout = sum (x_df['July'])
  return dfout
Xy_July = Xy.groupby(['cif_id']).apply(my_sum)
Xy_July.shape

def my_sum(x_df):
  dfout = sum (x_df['Aug'])
  return dfout
Xy_Aug = Xy.groupby(['cif_id']).apply(my_sum)
Xy_Aug.shape

def my_sum(x_df):
  dfout = sum (x_df['Sep'])
  return dfout
Xy_Sep = Xy.groupby(['cif_id']).apply(my_sum)
Xy_Sep.shape

def my_sum(x_df):
  dfout = sum (x_df['Oct'])
  return dfout
Xy_Oct = Xy.groupby(['cif_id']).apply(my_sum)
Xy_Oct.shape

def my_sum(x_df):
  dfout = sum (x_df['Nov'])
  return dfout
Xy_Nov = Xy.groupby(['cif_id']).apply(my_sum)
Xy_Nov.shape

def my_sum(x_df):
  dfout = sum (x_df['Dec'])
  return dfout
Xy_Dec = Xy.groupby(['cif_id']).apply(my_sum)
Xy_Dec.shape

X = pd.concat([Xy_Jan, Xy_Feb, Xy_March, Xy_Apr, Xy_May, Xy_June], axis=1)
X.head(13)

y = pd.concat([Xy_July, Xy_Aug, Xy_Sep, Xy_Oct, Xy_Nov, Xy_Dec], axis=1)
y.head(13)

from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split

#сделаем обучающую выборку

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = RS, shuffle=False)

net = MLPRegressor(hidden_layer_sizes=(6, 12, 6),verbose=False, \
                   early_stopping=True, shuffle=False, random_state=RS)

net.fit(X_train,y_train)

#prediction = net.predict(X_test)[0]
prediction = net.predict(X_test)
print (prediction)

def smape(predicted_values, true_values): 
    # metric
    return np.mean(np.abs((predicted_values - true_values) 
        / (np.abs(predicted_values) + np.abs(true_values))))

smape(prediction, y_test)

print(prediction)

pred = pd.DataFrame(prediction)

pred.head(13)

pred.shape

#let s form the final file

X_colomns = ['cif_id',	'dlk_cob_date',	'gi_smooth_3m', 'cu_age'] #take in work minimum columns

y_test = test_df[X_colomns]
y_test.head(20)

y_test.dlk_cob_date =  pd.to_datetime(y_test.dlk_cob_date) # convert object to date
y_test.head(45)

y_test.info()

#lets make new column month
y_test['month'] =  y_test['dlk_cob_date'].map(lambda x: 'month_'+str(x.month))
y_test.head(45)

#lets sort by columns client, month
y_test =  y_test.sort_values(by =['cif_id', 'month'], ascending=[True, True])
y_test.head(37)

df_nonbinary = pd.get_dummies(y_test['month'])
df_nonbinary.head(13)

#let s concatenate df

y = pd.concat([y_test, df_nonbinary], axis=1)
y.head(13)

lst = []
for n, s in zip (y.gi_smooth_3m, y.month_1): #make new column Jan with data
  lst.append(n*s) 
y['Jan'] = lst

y.head()

lst = []
for n, s in zip (y.gi_smooth_3m, y.month_2): #make new column Feb with data
  lst.append(n*s) 
y['Feb'] = lst

y.head()

lst = []
for n, s in zip (y.gi_smooth_3m, y.month_3): #make new column March with data
  lst.append(n*s) 
y['March'] = lst

y.head()

lst = []
for n, s in zip (y.gi_smooth_3m, y.month_4): #make new column Apr with data
  lst.append(n*s) 
y['Apr'] = lst

lst = []
for n, s in zip (y.gi_smooth_3m, y.month_5): #make new column May with data
  lst.append(n*s) 
y['May'] = lst

lst = []
for n, s in zip (y.gi_smooth_3m, y.month_6): #make new column June with data
  lst.append(n*s) 
y['June'] = lst
y.head()

def my_sum(x_df):
  dfout = sum (x_df['Jan'])
  return dfout
y_Jan = y.groupby(['cif_id']).apply(my_sum)
y_Jan.head(13)

def my_sum(x_df):
  dfout = sum (x_df['Feb'])
  return dfout
y_Feb = y.groupby(['cif_id']).apply(my_sum)
y_Feb.shape

def my_sum(x_df):
  dfout = sum (x_df['March'])
  return dfout
y_March = y.groupby(['cif_id']).apply(my_sum)
y_March.shape

def my_sum(x_df):
  dfout = sum (x_df['Apr'])
  return dfout
y_Apr = y.groupby(['cif_id']).apply(my_sum)
y_Apr.shape

def my_sum(x_df):
  dfout = sum (x_df['May'])
  return dfout
y_May = y.groupby(['cif_id']).apply(my_sum)
y_May.shape

def my_sum(x_df):
  dfout = sum (x_df['June'])
  return dfout
y_June = y.groupby(['cif_id']).apply(my_sum)
y_June.shape

#X_features = ['Jan', 'Feb', 'March', 'Apr', 'May', 'June']
y = pd.concat([y_Jan, y_Feb, y_March, y_Apr, y_May, y_June], axis=1)
y.head(13)

y.columns

X_features = range(0, 6, 1)
X_test = y[X_features]
X_test.head()

prediction = net.predict(X_test)
print (prediction)

df_pred = pd.DataFrame(prediction)
df_pred.columns = [ "July", "Aug", "Sep", "Oct", "Nov", "Dec"]
df_pred.head()

df_pred.shape

for index, row in y.iterrows():
  print (index, row[0]+row[1]+row[2]+row[3]+row[4]+row[5])

for i, r in df_pred.iterrows():
  print (i, r)

y['6m'] = 0

y.head()

lstInd = []

for index, row in y.iterrows():
  lstInd.append (index)
print(lstInd)

lstValue = []

for index, row in df_pred.iterrows():
  lstValue.append (row['July']+row['Aug']+row['Sep']+row['Oct']+row['Nov']+row['Dec'])
print(lstValue)

df_out = pd.DataFrame(lstValue, lstInd)

df_out.head()

df_out.to_csv("CUP_IT_predictions.csv", header=False, mode='w', index=True)

from google.colab import files
files.download('CUP_IT_predictions.csv')

